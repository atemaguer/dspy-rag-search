{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DSP_NOTEBOOK_CACHEDIR=cache\n"
     ]
    }
   ],
   "source": [
    "%set_env DSP_NOTEBOOK_CACHEDIR cache\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dsp\n",
    "from utils import get_retriever, get_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv('OPENAI_API_KEY')  # or replace with your API key (optional)\n",
    "colbert_server = 'http://ec2-44-228-128-229.us-west-2.compute.amazonaws.com:8893/api/search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = get_lm()\n",
    "rm = get_retriever(\"semantic-scholar\")\n",
    "dsp.settings.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsp.retrieveEnsemble([\"few-shot learners\", \"emergence\", \"in-context learning\"], k=5, by_prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'title': 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher',\n",
       "   'long_text': \"Language modelling provides a step towards intelligent communication systems by harnessing large repositories of written human knowledge to better predict and understand the world. In this paper, we present an analysis of Transformer-based language model performance across a wide range of model scales -- from models with tens of millions of parameters up to a 280 billion parameter model called Gopher. These models are evaluated on 152 diverse tasks, achieving state-of-the-art performance across the majority. Gains from scale are largest in areas such as reading comprehension, fact-checking, and the identification of toxic language, but logical and mathematical reasoning see less benefit. We provide a holistic analysis of the training dataset and model's behaviour, covering the intersection of model scale with bias and toxicity. Finally we discuss the application of language models to AI safety and the mitigation of downstream harms.\",\n",
       "   'paper_ids': {'DBLP': 'journals/corr/abs-2112-11446',\n",
       "    'ArXiv': '2112.11446',\n",
       "    'CorpusId': 245353475}}],\n",
       " [{'title': 'Language Models are Few-Shot Learners',\n",
       "   'long_text': \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.\",\n",
       "   'paper_ids': {'ArXiv': '2005.14165',\n",
       "    'DBLP': 'journals/corr/abs-2005-14165',\n",
       "    'MAG': '3030163527',\n",
       "    'CorpusId': 218971783}}],\n",
       " [{'title': 'PaLM: Scaling Language Modeling with Pathways',\n",
       "   'long_text': 'Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning , which drastically reduces the number of task-speciﬁc training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM). We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly eﬃcient training across multiple TPU Pods. We demonstrate continued beneﬁts of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the ﬁnetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A signiﬁcant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.',\n",
       "   'paper_ids': {'DBLP': 'journals/corr/abs-2204-02311',\n",
       "    'ArXiv': '2204.02311',\n",
       "    'CorpusId': 247951931}}]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm([\"scaling language models\",\t\"emergence in-context learning\", \"task-specific training\"], ensemble=True, k=3)\n",
    "rm(\"scaling language models\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('Who produced the album that included a re-recording of \"Lithium\"?', ['Butch Vig']),\n",
    "         ('Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?', ['Kevin Greutert']),\n",
    "         ('The heir to the Du Pont family fortune sponsored what wrestling team?', ['Foxcatcher', 'Team Foxcatcher', 'Foxcatcher Team']),\n",
    "         ('In what year was the star of To Hell and Back born?', ['1925']),\n",
    "         ('Which award did the first book of Gary Zukav receive?', ['U.S. National Book Award', 'National Book Award']),\n",
    "         ('What city was the victim of Joseph Druces working in?', ['Boston, Massachusetts', 'Boston']),]\n",
    "\n",
    "train = [dsp.Example(question=question, answer=answer) for question, answer in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = dsp.Type(prefix=\"Question:\", desc=\"${the question to be answered}\")\n",
    "answer = dsp.Type(prefix=\"Answer:\", desc=\"${a short factoid answer, often between 1 and 5 words}\", format=dsp.format_answers)\n",
    "\n",
    "qa_template = dsp.Template(instructions=\"Answer questions with short factoid answers.\", question=question(), answer=answer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = dsp.Type(\n",
    "    prefix=\"Context:\\n\",\n",
    "    desc=\"${sources that may contain relevant content}\",\n",
    "    format=dsp.passages2text\n",
    ")\n",
    "\n",
    "qa_template_with_passages = dsp.Template(\n",
    "    instructions=qa_template.instructions,\n",
    "    context=context(), question=question(), answer=answer()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program 1: RTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_then_read_QA(question: str) -> str:\n",
    "    demos = dsp.sample(train, k=5)\n",
    "    passages = rm(question, k=10)\n",
    "    \n",
    "    example = dsp.Example(question=question, context=passages, demos=demos)\n",
    "    example, completions = dsp.generate(qa_template_with_passages)(example, stage='qa')\n",
    "\n",
    "    return completions.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_then_read_QA(\"Query encoder\"), lm.inspect_history(n=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program 2: TOT\n",
    "\n",
    "This program performs the search step to retrieve the most relevant documents from the retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale = dsp.Type(\n",
    "    prefix=\"Rationale: Let's think step by step.\",\n",
    "    desc=\"${a step-by-step deduction that identifies the correct response, which will be provided below}\"\n",
    ")\n",
    "\n",
    "qa_template_with_CoT = dsp.Template(\n",
    "    instructions=qa_template.instructions,\n",
    "    context=context(), question=question(), rationale=rationale(), answer=answer()\n",
    ")\n",
    "\n",
    "search_rationale = dsp.Type(\n",
    "    prefix=\"Rationale: Let's think step by step. To answer this question, we first need to find out\",\n",
    "    desc=\"${the missing information}\"\n",
    ")\n",
    "\n",
    "search_query = dsp.Type(\n",
    "    prefix=\"Search Query:\",\n",
    "    desc=\"${a simple question for seeking the missing information}\"\n",
    ")\n",
    "\n",
    "rewrite_template = dsp.Template(\n",
    "    instructions=\"Write a search query that will help answer a complex question.\",\n",
    "    question=question(), rationale=search_rationale(), query=search_query()\n",
    ")\n",
    "\n",
    "condensed_rationale = dsp.Type(\n",
    "    prefix=\"Rationale: Let's think step by step. Based on the context, we have learned the following.\",\n",
    "    desc=\"${information from the context that provides useful clues}\"\n",
    ")\n",
    "\n",
    "hop_template = dsp.Template(\n",
    "    instructions=rewrite_template.instructions,\n",
    "    context=context(), question=question(), rationale=condensed_rationale(), query=search_query()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import deduplicate\n",
    "\n",
    "@dsp.transformation\n",
    "def qa_predict(example: dsp.Example, sc=True):\n",
    "    if sc:\n",
    "        example, completions = dsp.generate(qa_template_with_CoT, n=20, temperature=0.7)(example, stage='qa')\n",
    "        completions = dsp.majority(completions)\n",
    "    else:\n",
    "        example, completions = dsp.generate(qa_template_with_CoT)(example, stage='qa')\n",
    "    \n",
    "    return example.copy(answer=completions.answer)\n",
    "\n",
    "@dsp.transformation\n",
    "def multihop_search(example: dsp.Example, max_hops=2, k=10) -> dsp.Example:\n",
    "    example.context = []\n",
    "    \n",
    "    for hop in range(max_hops):\n",
    "        # Generate a query based\n",
    "        template = rewrite_template if hop == 0 else hop_template\n",
    "        example, completions = dsp.generate(template)(example, stage=f'h{hop}')\n",
    "\n",
    "        # Retrieve k results based on the query generated\n",
    "        passages = rm(completions.query, k=k)\n",
    "\n",
    "        # Update the context by concatenating old and new passages\n",
    "        example.context = deduplicate(example.context + passages)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihop_qa(question: str) -> str:\n",
    "    demos = dsp.sample(train, k=7)\n",
    "    x = dsp.Example(question=question, demos=demos)\n",
    "    \n",
    "    x = multihop_search(x)\n",
    "    x = qa_predict(x, sc=True)\n",
    "\n",
    "    return x.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihop_qa(\"Large Language Models are zero-shot reasoners\"), lm.inspect_history(n=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from router import Router\n",
    "from constants import DEFAULT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Router(lm, DEFAULT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' TOT']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(\"Find papers that ensemble generations of in-context learning across prompts, where each prompt has different demonstrating examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' TOT']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(\"Find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ST']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(\"BERT Language model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOT Queries Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Language Models are Few-Shot Learners\"\n",
    "abstract = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_title = \"Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP\"\n",
    "dsp_abstract = \"\"\"Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM). Existing work has combined these in simple \"retrieve-then-read\" pipelines in which the RM retrieves passages that are inserted into the LM prompt. To begin to fully realize the potential of frozen LMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that relies on passing natural language texts in sophisticated pipelines between an LM and an RM. DSP can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the LM and RM can handle more reliably. We have written novel DSP programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art in-context learning results and delivering 37-120%, 8-39%, and 80-290% relative gains against the vanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a contemporaneous self-ask pipeline, respectively.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dsp.Example(question=query, context= dsp_title + \"\\n\" + dsp_abstract, demos=[])\n",
    "_, completions = dsp.generate(QUERY_PROCESSING_TEMPLATE)(example, stage='qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question: Do you think the paper above answers this question: ${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP\n",
      "Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM). Existing work has combined these in simple \"retrieve-then-read\" pipelines in which the RM retrieves passages that are inserted into the LM prompt. To begin to fully realize the potential of frozen LMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that relies on passing natural language texts in sophisticated pipelines between an LM and an RM. DSP can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the LM and RM can handle more reliably. We have written novel DSP programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art in-context learning results and delivering 37-120%, 8-39%, and 80-290% relative gains against the vanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a contemporaneous self-ask pipeline, respectively.\n",
      "\n",
      "Question: Do you think the paper above answers this question: find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling language models, emergence, in-context learning, many tasks, task-specific training\n",
      "['On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model', 'Many recent studies on large-scale language models have reported successful in-context zero- and few-shot learning ability. However, the in-depth analysis of when in-context learning occurs is still lacking. For example, it is unknown how in-context learning performance changes as the training corpus varies. Here, we investigate the effects of the source and size of the pretraining corpus on in-context learning in HyperCLOVA, a Korean-centric GPT-3 model. From our in-depth investigation, we introduce the following observations: (1) in-context learning performance heavily depends on the corpus domain source, and the size of the pretraining corpus does not necessarily determine the emergence of in-context learning, (2) in-context learning ability can emerge when a language model is trained on a combination of multiple corpora, even when each corpus does not result in in-context learning on its own, (3) pretraining with a corpus related to a downstream task does not always guarantee the competitive in-context learning performance of the downstream task, especially in the few-shot setting, and (4) the relationship between language modeling (measured in perplexity) and in-context learning does not always correlate: e.g., low perplexity does not always imply high in-context few-shot learning performance.']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtot_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfind a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/colbert/lib/python3.8/site-packages/dsp/primitives/primitives.py:20\u001b[0m, in \u001b[0;36mshallow_copy_example_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m args \u001b[39m=\u001b[39m [dsp\u001b[39m.\u001b[39mExample(arg) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, dsp\u001b[39m.\u001b[39mExample) \u001b[39melse\u001b[39;00m arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[1;32m     19\u001b[0m kwargs \u001b[39m=\u001b[39m {key: dsp\u001b[39m.\u001b[39mExample(value) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, dsp\u001b[39m.\u001b[39mExample) \u001b[39melse\u001b[39;00m value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> 20\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mtot_pipeline\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m passage \u001b[38;5;129;01min\u001b[39;00m passages:\n\u001b[0;32m---> 14\u001b[0m         example \u001b[38;5;241m=\u001b[39m dsp\u001b[38;5;241m.\u001b[39mExample(question\u001b[38;5;241m=\u001b[39mquery, context\u001b[38;5;241m=\u001b[39m \u001b[43mpassage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpassage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, demos\u001b[38;5;241m=\u001b[39mdemos)\n\u001b[1;32m     15\u001b[0m         _, completions \u001b[38;5;241m=\u001b[39m dsp\u001b[38;5;241m.\u001b[39mgenerate(QUERY_PROCESSING_TEMPLATE)(example, stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39manswer\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39manswer\u001b[38;5;241m.\u001b[39mlower():\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "tot_pipeline(\"find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Settings' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Settings' object is not callable"
     ]
    }
   ],
   "source": [
    "dsp.settings(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paper_id': '2108.01928',\n",
       "  'long_text': ' Few-Shot Learning The term few-shot learning refers to the practice of only providing a few examples when training a model, compared to the typical approach of using large datasets (Wang et al., 2020). In the NLP domain, recent work by Brown et al. (2020) suggests to use these few examples only in the context, as opposed to actually training with it. Fittingly, they call this approach in-context learning. Here, they condition the model on a natural language description of the task together with a few demonstrations. Their experiments reveal that the larger the model, the better its in-context learning capabilities. Our approach is very similar to in-context learning, with the difference that we do not provide a description of the task and utilize natural language templates for the relations.'},\n",
       " {'paper_id': '2210.05572',\n",
       "  'long_text': ' Few-Shot Learning. Few-shot learning aims at quickly generalizing the model to new tasks with a few labeled samples (Wang et al., 2020). Existing works can be categorized into metric-learning based approaches that aims to establish similarity or dissimilarity between classes (Vinyals et al., 2016; Sung et al., 2017; Snell et al., 2017; Oreshkin et al., 2019; Cao et al., 2021; Ye et al., 2021), and optimization based approach seeks to learn a good initialization point that can adapt to new tasks within a few parameter updates (Finn et al., 2017; Nichol et al., 2018; Rusu et al., 2019; Yao et al., 2021b; Peng & Pan, 2022). For recommendation problem, few-shot learning is leveraged to solve the cold-start problem, where the'},\n",
       " {'paper_id': '2205.09088',\n",
       "  'long_text': ' 8.2. Few Shot Learning The relationships between the elements in the KG are far from complete, especially for unusual relationships, making it incredibly difficult to capture hidden examples of these relationships. Few shot learning is a technique proposed for learning in case the training data is low, which has previously been shown to have significant performance in image vision tasks [239]. Few attempts have been made to incorporate few-shot learning strategies into the knowledge graph, aimed at finding hidden examples of a relation with which only certain triples are related [227] [225] [224] [226] [240]. Although these are acceptable efforts, their low performance suggests that few-shot learning in graphs is an open research area.'},\n",
       " {'paper_id': '2204.12668',\n",
       "  'long_text': ' 2.2 Few-Shot Adaptation Methods Few-shot learning, which aims at learning with a limited number of labeled examples, is a meaningful way to bridge the gap between AI and humans and relieve the burden of collecting and annotating large-scale labeled data. This is especially the case for text matching tasks, as the volume of sentence-pair data is considerably large and the manual determination of the semantic relationships for each pair of text is costly. It would be more efficient to solve the current few-shot learning problem with the help of a trained model on another label-rich task or dataset than spending a lot of time and labor costs in constructing a new dataset for the current task. In this way, the problem of few-shot learning is transformed into a specific form of adaptation methods, which aim to eliminate the discrepancy between the source and target data distributions.'},\n",
       " {'paper_id': '2104.07650',\n",
       "  'long_text': ' [14] Bowen Dong, Yuan Yao, Ruobing Xie, Tianyu Gao, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. 2020. Meta-Information Guided Meta-Learning for Few-Shot Relation Classification. In Proceedings of COLING 2020. [15] Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making Pre-trained Language Models Better Few-shot Learners. In Proceedings of ACL. [16] Tianyu Gao, Xu Han, Zhiyuan Liu, and Maosong Sun. 2019. Hybrid AttentionBased Prototypical Networks for Noisy Few-Shot Relation Classification. In Proceedings of AAAI. [17] Tianyu Gao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. 2020. Neural Snowball for Few-Shot Relation Learning. In Proceedings of AAAI 2020. [18] Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang. 2021. PPT: Pretrained Prompt Tuning for Few-shot Learning. CoRR abs/2109.04332 (2021). arXiv:2109.04332 https://arxiv.org/abs/2109.04332 [19] Zhijiang Guo, Guoshun Nan, Wei Lu, and Shay B Cohen. 2020. Learning Latent Forests for Medical Relation Extraction.. In IJCAI. 3651–3657.'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm(\"few-shot learners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question:\n",
      "${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts\n",
      "Large sparsely-activated models have obtained excellent performance in multiple domains. However, such models are typically trained on a single modality at a time. We present the Language-Image MoE, LIMoE , a sparse mixture of experts model capable of multimodal learning. LIMoE accepts both images and text simultaneously, while being trained using a contrastive loss. MoEs are a natural ﬁt for a multimodal backbone, since expert layers can learn an appropriate partitioning of modalities. However, new challenges arise; in particular, training stability and balanced expert utilization, for which we propose an entropy-based regularization scheme. Across multiple scales, we demonstrate remarkable performance improvement over dense models of equivalent computational cost. LIMoE -L/16 trained comparably to CLIP-L/14 achieves 78.6% zero-shot ImageNet accuracy (vs. 76.2%), and when further scaled to H/14 (with additional data) it achieves 84.1%, comparable to state-of-the-art methods which use larger custom per-modality backbones and pre-training schemes. We analyse the quantitative and qualitative behavior of LIMoE , and demonstrate phenomena such as differing treatment of the modalities and the organic emergence of modality-speciﬁc experts.\n",
      "\n",
      "Question:\n",
      "find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question:\n",
      "${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "The Unsurprising Effectiveness of Pre-Trained Vision Models for Control\n",
      "Recent years have seen the emergence of pretrained representations as a powerful abstraction for AI applications in computer vision, natural language, and speech. However, policy learning for control is still dominated by a tabula-rasa learning paradigm, with visuo-motor policies often trained from scratch using data from deployment environments. In this context, we revisit and study the role of pre-trained visual representations for control, and in particular representations trained on large-scale computer vision datasets. Through extensive empirical evaluation in diverse control domains (Habitat, DeepMind Control, Adroit, Franka Kitchen), we isolate and study the importance of different representation training methods, data augmentations, and feature hierarchies. Overall, we find that pre-trained visual representations can be competitive or even better than ground-truth state representations to train control policies. This is in spite of using only out-of-domain data from standard vision datasets, without any in-domain data from the deployment environments.\n",
      "\n",
      "Question:\n",
      "find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question:\n",
      "${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "Multi-label Iterated Learning for Image Classification with Label Ambiguity\n",
      "Transfer learning from large-scale pre-trained models has become essential for many computer vision tasks. Recent studies have shown that datasets like ImageNet are weakly labeled since images with multiple object classes present are assigned a single label. This ambiguity biases models towards a single prediction, which could result in the suppression of classes that tend to co-occur in the data. Inspired by language emergence literature, we propose multi-label iterated learning (MILe) to incorporate the inductive biases of multi-label learning from single labels using the framework of iterated learning. MILe is a simple yet effective procedure that builds a multi-label description of the image by propagating binary predictions through successive generations of teacher and student networks with a learning bottleneck. Experiments show that our approach exhibits systematic benefits on ImageNet accuracy as well as ReaL F1 score, which indicates that MILe deals better with label ambiguity than the standard training procedure, even when fine-tuning from self-supervised weights. We also show that MILe is effective reducing label noise, achieving state-of-the-art performance on real-world large-scale noisy data such as WebVision. Furthermore, MILe improves performance in class incremental settings such as IIRC and it is robust to distribution shifts. Code: https://github.com/rajeswar18/MILe\n",
      "\n",
      "Question:\n",
      "find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question:\n",
      "${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "Applications of Machine Learning in Wealth Management\n",
      "Compared with traditional statistics, ML algorithms reduce dependencies on structural models and parametric assumptions. Instead, there is a focus on performance of models across training, validation, and out-of-sample testing, requiring larger amounts of representative data. 3 The philosophy is closely aligned with classic frequentist approaches in statistics: “Let the data do the talking.” Distinguishing features of recent ML algorithms are: (1) high dimensional parameter sets, (2) nonlinear relationships, and (3) a much-diminished role of structural assumptions. Another common feature involves constructing high-performing models from ensembles of relatively simple, low-performing models Israel suggest that these concepts are evolutionary rather than revolu-tionary. Regardless, the emergence of a tidal wave of micro-level data and powerful ML algorithms enables numerous applications to wealth management and shifts research away from financial theory toward data-driven approaches. We emphasize ABSTRACT T his paper provides a targeted review of machine learning methods that are impacting the field of wealth management. This is an area of great breadth and dynamic growth, and we focus on applications that in our experience are delivering benefits in practice to wealth management businesses by improving investment performance and enabling personalized services at scale. We highlight novel approaches to customized financial planning systems and deep learning algorithms with novel data sources linked to natural language processing concepts. We also discuss emerging challenges and opportunities that may shape the future path of this rapidly evolving area.\n",
      "\n",
      "Question:\n",
      "find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question:\n",
      "${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "Does Deep Learning Learn to Abstract? A Systematic Probing Framework\n",
      "Abstraction is a desirable capability for deep learning models, which means to induce abstract concepts from concrete instances and flexibly apply them beyond the learning context. At the same time, there is a lack of clear understanding about both the presence and further characteristics of this capability in deep learning models. In this paper, we introduce a systematic probing framework to explore the abstraction capability of deep learning models from a transferability perspective. A set of controlled experiments are conducted based on this framework, providing strong evidence that two probed pre-trained language models (PLMs), T5 and GPT2, have the abstraction capability. We also conduct in-depth analysis, thus shedding further light: (1) the whole training phase exhibits a\"memorize-then-abstract\"two-stage process; (2) the learned abstract concepts are gathered in a few middle-layer attention heads, rather than being evenly distributed throughout the model; (3) the probed abstraction capabilities exhibit robustness against concept mutations, and are more robust to low-level/source-side mutations than high-level/target-side ones; (4) generic pre-training is critical to the emergence of abstraction capability, and PLMs exhibit better abstraction with larger model sizes and data scales.\n",
      "\n",
      "Question:\n",
      "find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Does the following piece of text fullfil this question? The text should be relevant to the question below. Give a Yes or No answer.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Text:\n",
      "${text that might contain information that fulfills the question}\n",
      "\n",
      "Question:\n",
      "${a question from a user looking for a paper}\n",
      "\n",
      "Answer: ${a Yes, or No answer}\n",
      "\n",
      "---\n",
      "\n",
      "Text:\n",
      "Ernie-Gram BiGRU Attention: An Improved Multi-Intention Recognition Model for Air Traffic Control\n",
      "In recent years, the emergence of large-scale pre-trained language models has made transfer learning possible in natural language processing, which overturns the traditional model architecture based on recurrent neural networks (RNN). In this study, we constructed a multi-intention recognition model, Ernie-Gram_Bidirectional Gate Recurrent Unit (BiGRU)_Attention (EBA), for air traffic control (ATC). Firstly, the Ernie-Gram pre-training model is used as the bottom layer of the overall architecture to implement the encoding of text information. The BiGRU module that follows is used for further feature extraction of the encoded information. Secondly, as keyword information is very important in Chinese radiotelephony communications, the attention layer after the BiGRU module is added to realize the extraction of keyword information. Finally, two fully connected layers (FC) are used for feature vector fusion and outputting intention classification vector, respectively. We experimentally compare the effects of two different tokenizer tools, the BERT tokenizer tool and Jieba tokenizer tool, on the final performance of the Bert model. The experimental results reveal that although the Jieba tokenizer tool has considered word information, the effect of the Jieba tokenizer tool is not as good as that of the BERT tokenizer tool. The final model’s accuracy is 98.2% in the intention recognition dataset of the ATC instructions, which is 2.7% higher than the Bert benchmark model and 0.7–3.1% higher than other improved models based on BERT.\n",
      "\n",
      "Question:\n",
      "find a paper that demonstrates how scaling language models leads to emergence of a phenomena called in-context learning where the model learns to perform many tasks without task-specific training\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dsp.templates.template_v3.Type at 0x7fa389d27460>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('colbert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d58fc6146dee07272d5a69f592212ecbce79129f978d761ca5cef75b4916b3a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
