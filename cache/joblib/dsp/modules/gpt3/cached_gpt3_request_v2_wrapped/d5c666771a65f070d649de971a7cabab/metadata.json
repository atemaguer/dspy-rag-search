{"duration": 2.269862174987793, "input_args": {"**": "{'frequency_penalty': 0, 'max_tokens': 150, 'model': 'text-davinci-002', 'n': 1, 'presence_penalty': 0, 'prompt': \"Write a search query that will help answer a complex question.\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let's think step by step. Based on the context, we have learned the following. ${information from the context that provides useful clues}\\n\\nSearch Query: ${a simple question for seeking the missing information}\\n\\n---\\n\\nContext:\\n[1] \u00ab2104.07198v2.txt | with mean-pooling on BERT token embeddings. ColBERT (Khattab and Zaharia, 2020) is a dense model with token-level late interactions between queries and passages, which are encoded separately. BERT Base & Large (Nogueira and Cho, 2019) are dense models that fully leverage the interaction between a query and passage. They are often used to re-rank fast BM25 results.\u00bb\\n[2] \u00ab2208.00511v1.txt | 2.1 Bi-Encoder DPR Multi-Vector DPR. Among the bi-encoder models, ColBERT (Khattab and Zaharia, 2020) is a representative architecture with state-of-the-art retrieval effectiveness. The scoring function of ColBERT can be written as the maxsim operation: X simMaxSim (q, p) , max Eqi * Epj , (2) i\u2208|q| j\u2208|p| where Eqi and Epj denotes the i-th and j-th BERT contextualized query and passage token embeddings, respectively. This is known as the MaxSim operation which leverages all the token information of BERT, as shown in Fig. 2(a). Despite of its effectiveness, ColBERT requires to store all the token embeddings in the corpus for offline score computation.\u00bb\\n[3] \u00ab2209.01335v1.txt | Neural machine translations of MS MARCO passages are used to fine-tune the model. 1 Introduction ColBERT (Khattab and Zaharia, 2020) is a dense retrieval model for performing retrieval over English documents with queries written in English. It is designed as a two-stage retrieval model that (1) selects a set of candidate passages using an approximate nearest neighbor approach and (2) ranks those passages based on the sum of the most similar terms to each term in the query.\u00bb\\n[4] \u00ab2201.08471v1.txt | 3 ColBERT-X ColBERT is a multi-stage dense retrieval model that uses monolingual BERT [7] to encode both query and document terms. It employs a late-interaction mechanism, MaxSim, that computes the similarity between the encoded query and document term representations. Computing MaxSim for every query and document term pair in the collection is not feasible, so ColBERT has two ways to reduce the number of required similarity comparisons: reranking or end-toend retrieval. In reranking, a retrieval system such as BM25 generates an initial ranked list, which is then reranked using ColBERT's MaxSim operation. The disadvantage of such a cascaded pipeline is that the overall recall of the system is limited to the recall of the initial ranked list. In the context of CLIR systems, we face the additional complexity of crossing the language barrier that further affects recall. We thus restricted our work to end-to-end (E2E) retrieval.\u00bb\\n[5] \u00ab2203.13088v1.txt | 7 CONCLUSION In this paper, we proposed ColBERTer, an efficient and effective retrieval model that improves the storage efficiency, the retrieval complexity, and the interpretability of the ColBERT architecture along the effectiveness Pareto frontier. To this end, ColBERTer learns whole-word representations that exclude contextualized stopwords, yielding 2.5\u00d7 fewer vectors than ColBERT while supporting user-friendly query\u2013document scoring patterns at the level of whole words. ColBERTer also uses a multi-task, multi-stage training objective-as well as an optional lexical matching component-that together enable it to aggressively reduce the vector dimension to 1. Extensive empirical evaluation shows that ColBERTer is highly effective on MS MARCO and TREC-DL and highly robust out of domain, while demonstrating highly-competitive storage efficiency with prior dense and sparse models. REFERENCES [1] 2015. Meta-analysis in clinical trials revisited. Contemporary Clinical Trials 45 (2015), 139\u2013145. https://doi.org/10.1016/j.cct.2015.09.002 10th Anniversary Special Issue.\u00bb\\n\\nQuestion: ColBERT Information Retrieval\\n\\nRationale: Let's think step by step. Based on the context, we have learned the following.\", 'temperature': 0.0, 'top_p': 1}"}}