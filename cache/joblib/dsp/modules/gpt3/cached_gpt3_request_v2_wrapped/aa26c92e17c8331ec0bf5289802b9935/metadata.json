{"duration": 0.7744629383087158, "input_args": {"**": "{'frequency_penalty': 0, 'logprobs': 5, 'max_tokens': 150, 'model': 'text-davinci-002', 'n': 20, 'presence_penalty': 0, 'prompt': 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which award did the first book of Gary Zukav receive?\\nAnswer: U.S. National Book Award\\n\\nQuestion: The heir to the Du Pont family fortune sponsored what wrestling team?\\nAnswer: Foxcatcher\\n\\nQuestion: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\\nAnswer: Kevin Greutert\\n\\nQuestion: Who produced the album that included a re-recording of \"Lithium\"?\\nAnswer: Butch Vig\\n\\nQuestion: What city was the victim of Joseph Druces working in?\\nAnswer: Boston, Massachusetts\\n\\nQuestion: In what year was the star of To Hell and Back born?\\nAnswer: 1925\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n[1] \u00ab2212.14024v1.txt | Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Rationale-augmented ensembles in language models. arXiv preprint arXiv:2207.00747, 2022b. Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022c. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022. Wiher, G., Meister, C., and Cotterell, R. On decoding strategies for neural text generators. arXiv preprint arXiv:2203.15721, 2022. Xiong, W., Li, X. L., Iyer, S., Du, J., Lewis, P., Wang, W. Y., Mehdad, Y., Yih, W.-t., Riedel, S., Kiela, D., et al. Answering complex open-domain questions with multihop dense retrieval. arXiv preprint arXiv:2009.12756, 2020. URL https://arxiv.org/abs/2009.12756.\u00bb\\n[2] \u00ab2212.09597v1.txt | Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. Emergent abilities of large language models. CoRR, abs/2206.07682. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, December 6-14, 2022, virtual. Peifeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen, and Xiang Ren. 2022c. PINTO: faithful language reasoning using prompt-generated rationales. CoRR, abs/2211.01562.\u00bb\\n[3] \u00ab2210.05075v1.txt | Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models. ArXiv, abs/2206.07682, 2022a. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022b. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pp. 38\u201345, 2020.\u00bb\\n[4] \u00ab2210.05075v1.txt | This paper introduces reflection of thought, a new idea of eliciting the numerical reasoning knowledge hidden in pre-trained LMs through probing with simple anchor numbers. Reflection of thought, in principle, allows models to unveil the underlying reasoning process by varying inputs at test time, so it does not need any extra training or labeled data. To inversely elicit arithmetic relationships in LMs through anchor numbers, we propose S O L I S, a novel method to transform and formulate this problem to\u00bb\\n[5] \u00ab1701.02163v1.txt | Valentina Franzoni and Alfredo Milani. 2016. A semantic comparison of clustering algorithms for the evaluation of web-based similarity measures, LNCS Valentina Franzoni and Alfredo Milani. 2014. Heuristic semantic walk for concept chaining in collaborative networks. Int. J. Web Inf. Syst. 10, 1 (2014). DOI:https://doi.org/10.1108/IJWIS-112013-0031 C.H.C. Leung, Y. Li, A. Milani, and V. Franzoni. 2013. Collective evolutionary concept distance based query expansion for effective web document retrieval, LNCS S. Pallottelli, V. Franzoni, and A. Milani. 2016. Multi-path traces in semantic graphs for latent knowledge elicitation. In Proceedings - International Conference on Natural Computation. DOI:https://doi.org/10.1109/ICNC.2015.7378004 Peter D. Turney. 2002. Mining the Web for Synonyms: {PMI-IR} versus {LSA} on {TOEFL}. CoRR cs.LG/0212 (2002). Author copy .\u00bb\\n[6] \u00ab2212.09656v1.txt | The few-shot capability of LLMs may reduce the costs for solving QA tasks, as it allows one to implement QA systems for different domains without needing a specific annotated dataset. In addition, recent studies showed that adding a chain-of-thought (CoT) reasoning step before answering significantly improves LLMs\\' zero or few-shot effectiveness on diverse QA benchmarks [16]. In this work, we propose Visconde,3 a QA system that combines a state-of-the-art retriever and a few-shot (CoT) approach to induce an\u00bb\\n[7] \u00ab2210.05075v1.txt | Numerical Reasoning in Giant Language Models Recent works demonstrate that with proper prompting, giant language models (e.g., GPT-3) perform much better than smaller ones on several reasoning tasks (Wei et al., 2022b;a; Kojima et al., 2022; Li et al., 2022; Zhou et al., 2022; Wang et al., 2022). For example, with the chain-of-thought prompting, the few-shot PaLM model (Chowdhery et al., 2022) can beat the previous best fine-tuned model on math word problems. However, their conclusions do not generalize to non-giant language models. Different from them, our method can be simultaneously applied to language models ranging from millions (e.g., BART) to billions (e.g., GPT-3). Moreover, our work is orthogonal to these giant LMs and can be complementary to each other. For example, Section 5 shows that our approach can further boost the numerical reasoning capability of GPT-3 with chain-of-thought prompting.\u00bb\\n[8] \u00ab2212.09656v1.txt | 12496 Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., Zhou, D.: Self-consistency improves chain of thought reasoning in language models (2022). https://doi.org/10.48550/ARXIV.2203.11171, https://arxiv.org/abs/ 2203.11171 Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., Zhou, D.: Chain of thought prompting elicits reasoning in large language models (2022). https://doi.org/10.48550/ARXIV.2201.11903, https://arxiv.org/abs/ 2201.11903 Xiong, W., Gupta, A., Toshniwal, S., Mehdad, Y., Yih, W.t.: Adapting pretrained text-to-text models for long text sequences (2022). https://doi.org/10.48550/ARXIV.2209.10052, https://arxiv.org/abs/2209.\u00bb\\n\\nQuestion: Chain of Thought Elicits\\n\\nRationale: Let\\'s think step by step. [1] \u00ab2212.14024v1.txt | Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Rationale-augmented ensembles in language models. arXiv preprint arXiv:2207.00747, 2022b. Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022c. Wei, J., Wang, X., Schuurmans, D., Bosma\\n\\nAnswer:', 'temperature': 0.7, 'top_p': 1}"}}