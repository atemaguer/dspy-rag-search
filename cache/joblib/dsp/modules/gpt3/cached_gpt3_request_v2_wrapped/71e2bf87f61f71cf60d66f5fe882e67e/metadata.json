{"duration": 2.0217249393463135, "input_args": {"**": "{'frequency_penalty': 0, 'max_tokens': 150, 'model': 'text-davinci-002', 'n': 1, 'presence_penalty': 0, 'prompt': 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which award did the first book of Gary Zukav receive?\\nAnswer: U.S. National Book Award\\n\\nQuestion: The heir to the Du Pont family fortune sponsored what wrestling team?\\nAnswer: Foxcatcher\\n\\nQuestion: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\\nAnswer: Kevin Greutert\\n\\nQuestion: Who produced the album that included a re-recording of \"Lithium\"?\\nAnswer: Butch Vig\\n\\nQuestion: What city was the victim of Joseph Druces working in?\\nAnswer: Boston, Massachusetts\\n\\nQuestion: In what year was the star of To Hell and Back born?\\nAnswer: 1925\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n[1] \u00abtitle->Retrieval Enhanced Data Augmentation for Question Answering on Privacy Policies | abstract->Prior studies in privacy policies frame the question answering (QA) tasks as identifying the most relevant text segment or a list of sentences from the policy document for a user query. However, annotating such a dataset is challenging as it requires speci\ufb01c domain expertise (e.g., law academics). Even if we manage a small-scale one, a bottleneck that re-mains is that the labeled data are heavily im-balanced (only a few segments are relevant) \u2013 limiting the gain in this domain. Therefore, in this paper, we develop a novel data augmentation framework based on ensembling retriever models that captures the relevant text segments from unlabeled policy documents and expand the positive examples in the training set. In ad-dition, to improve the diversity and quality of the augmented data, we leverage multiple pre-trained language models (LMs) and cascaded them with noise reduction oracles. Using our augmented data on the PrivacyQA benchmark, we elevate the existing baseline by a large mar-gin (10% F1) and achieve a new state-of-the-art F1 score of 50%. Our ablation studies provide further insights into the effectiveness of our approach.\u00bb\\n[2] \u00abtitle->Symbolic Data Augmentation for Assisted Neural Reasoning | abstract->Recent progress in various language processing tasks which require multi-step reasoning process in commonsense or scientific domains, are usually achieved by large-scale language models. While these models have achieved decent performance, their parameter number is becoming increasingly difficult for commodity hardware to handle. In this work, we propose a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher (usually neural) and a symbolic knowledge retriever. The annotations by each subannotator generated are combined and sent along with the original input to the target language model. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters, and establish the state-of-the-art single model performance on OPENBOOKQA.\u00bb\\n\\nQuestion: Which paper introduced the paradigm of retriever augmentation of language models(LM)\\n\\nRationale: Let\\'s think step by step.', 'temperature': 0.0, 'top_p': 1}"}}