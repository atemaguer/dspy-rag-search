{"duration": 5.596428871154785, "input_args": {"**": "{'frequency_penalty': 0, 'logprobs': 5, 'max_tokens': 150, 'model': 'text-davinci-002', 'n': 20, 'presence_penalty': 0, 'prompt': 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which award did the first book of Gary Zukav receive?\\nAnswer: U.S. National Book Award\\n\\nQuestion: The heir to the Du Pont family fortune sponsored what wrestling team?\\nAnswer: Foxcatcher\\n\\nQuestion: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\\nAnswer: Kevin Greutert\\n\\nQuestion: Who produced the album that included a re-recording of \"Lithium\"?\\nAnswer: Butch Vig\\n\\nQuestion: What city was the victim of Joseph Druces working in?\\nAnswer: Boston, Massachusetts\\n\\nQuestion: In what year was the star of To Hell and Back born?\\nAnswer: 1925\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n[1] \u00ab2210.06345v1.txt | Omar Khattab and Matei Zaharia. ColBERT: Efficient and effective passage search via contextualized late interaction over BERT. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 39\u201348. Association for Computing Machinery, New York, NY, USA, July 2020. ISBN 9781450380164. doi: 10.1145/3397271. 3401075. Omar Khattab, Christopher Potts, and Matei Zaharia. Relevance-guided supervision for OpenQA with ColBERT. Transactions of the Association for Computational Linguistics, 9:929\u2013944, September 2021. ISSN 2307-387X. doi: 10.1162/tacl\\\\_a\\\\_00405. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are Zero-Shot reasoners. May 2022. Wouter Kool, Herke Van Hoof, and Max Welling. Stochastic beams and where to find them: The Gumbel-Top-k trick for sampling sequences without replacement. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 3499\u20133508. PMLR, 2019a.\u00bb\\n[2] \u00ab2212.09597v1.txt | (2022) indicates that LMs are also zero-shot reasoners without needing extra exemplars. By only concatenating \"Let\\'s think step by step\", LMs can consciously generate reasoning steps. Multi-Stage. When human beings are reasoning, it is usually challenging to come up with the whole reasoning process in one stroke. A more intuitive solution is to decompose a complex problem into simpler sub-problems and reason stage by stage. Similarly, this series of works aims to transform previous one-stage prompting into multistage prompting. Press et al. (2022) explicitly defines follow-up questions and intermediate answers in prompts to narrow the compositionality gap in LMs. Jung et al. (2022) regard the output of each stage as a separate new question while Zhou et al.\u00bb\\n[3] \u00ab2212.09597v1.txt | Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2022. Decomposed prompting: A modular approach for solving complex tasks. CoRR, abs/2210.02406. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. CoRR, abs/2205.11916. Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang. 2015. Parsing Algebraic Word Problems into Equations. Transactions of the Association for Computational Linguistics, 3:585\u2013597. Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. MAWPS: A math word problem repository. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1152\u20131157, San Diego, California. Association for Computational Linguistics. Ranjay Krishna, Donsuk Lee, Li Fei-Fei, and Michael S. Bernstein. 2022. Socially situated artificial intelligence enables learning from human interaction. Proceedings of the National Academy of Sciences, 119(39):e2115730119.\u00bb\\n[4] \u00ab2210.05075v1.txt | Minghao Hu, Yuxing Peng, Zhen Huang, and Dongsheng Li. A multi-type multi-span network for reading comprehension that requires discrete reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 1596\u20131606, 2019. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7871\u20137880, 2020. Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858, 2022.\u00bb\\n[5] \u00ab2105.08318v2.txt | In this paper, we explore the possibility of zero-shot learning in RecSys, to enable generalization from an old dataset to an entirely new dataset. We develop an algorithm, dubbed ZEro-Shot Recommenders (ZESR EC), that is trained on an old dataset and generalize to a new one where there are neither overlapping users nor overlapping items, a setting that contrasts typical cross-domain RecSys that has either overlapping users or items. Different from previous methods that use categorical item indices (i.e., item ID), ZESR EC uses items\\' generic features, such as natural-language descriptions, product images, and videos, as their continuous indices, and therefore naturally generalizes to any unseen items. In terms of users, ZESR EC builds upon recent advances on sequential RecSys to represent users using their interactions with items, thereby generalizing to unseen users as well.\u00bb\\n[6] \u00ab2207.12515v1.txt | \u2022 Big Models: Recently, Foundation Models such as Large Language Models (LLM) have achieved surprisingly good performance in many AI sub-fields, which have the advantages of emergent capabilities from model size, extracting useful information based on self-supervision, unifying various downstream tasks based on pre-training, fine-tuning and prompting, as well as generalizing to zero-shot or few-shot cases [31, 290]. Many powerful foundation models have been developed for natural language tasks such as T5 [231], GPT-3 [35], OPT [335] and PaLM [69], which show impressive performance on language understanding, generation and reasoning tasks.\u00bb\\n[7] \u00ab2206.02873v5.txt | Additionally, larger language models demonstrated stronger zero-shot and few-shot capabilities compared to smaller models. Brown et al. [3] presented GPT-3, a language model with 175 billion parameters. The authors evaluated the model\\'s ability to learn from a few examples and demonstrated that scaling up the number of parameters greatly improves zero-shot and few-shot effectiveness. Wei et al. [44] presented instruction tuning, a novel method to improve the zero-shot learning capacity of scaled language models by providing task-specific instructions using natural language.\u00bb\\n[8] \u00ab2212.09597v1.txt | 6 Future Directions Even though numerous works have been proposed for reasoning with language model prompting, there remain some potential directions: Theoretical Principle of Reasoning. LMs have been demonstrated to have emergent zero-shot learning and reasoning abilities (Wei et al., 2022b; Wang et al., 2022g; Wei et al., 2022a). To uncover the mystery of such a success, many researchers have empirically explored the role of in-context learning (Ye and Durrett, 2022; Liu et al., 2022a) and rationales (Min et\u00bb\\n[9] \u00ab2205.08084v2.txt | 4.2 Zero-Shot Recommendation The unique advantage of using a pretrained language model as the foundation is that it can judge the likelihood of any event by expressing the event in natural language. To corroborate this statement, in Figure 7 we verify M6-Rec\\'s ability to perform zeroshot ranking on three datasets of different domains, using the zeroshot method described in Subsection 3.2. Moreover, after fitting the language loss on a few samples, M6-Rec can match the performance of a traditional ID-based ranker trained on a million samples.\u00bb\\n\\nQuestion: Large Language Models are zero-shot reasoners\\n\\nRationale: Let\\'s think step by step.', 'temperature': 0.7, 'top_p': 1}"}}