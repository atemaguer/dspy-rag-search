{"duration": 4.038635015487671, "input_args": {"**": "{'frequency_penalty': 0, 'logprobs': 5, 'max_tokens': 150, 'model': 'text-davinci-002', 'n': 20, 'presence_penalty': 0, 'prompt': 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which award did the first book of Gary Zukav receive?\\nAnswer: U.S. National Book Award\\n\\nQuestion: The heir to the Du Pont family fortune sponsored what wrestling team?\\nAnswer: Foxcatcher\\n\\nQuestion: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\\nAnswer: Kevin Greutert\\n\\nQuestion: Who produced the album that included a re-recording of \"Lithium\"?\\nAnswer: Butch Vig\\n\\nQuestion: What city was the victim of Joseph Druces working in?\\nAnswer: Boston, Massachusetts\\n\\nQuestion: In what year was the star of To Hell and Back born?\\nAnswer: 1925\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n[1] \u00ab2104.07198v2.txt | with mean-pooling on BERT token embeddings. ColBERT (Khattab and Zaharia, 2020) is a dense model with token-level late interactions between queries and passages, which are encoded separately. BERT Base & Large (Nogueira and Cho, 2019) are dense models that fully leverage the interaction between a query and passage. They are often used to re-rank fast BM25 results.\u00bb\\n[2] \u00ab2208.00511v1.txt | 2.1 Bi-Encoder DPR Multi-Vector DPR. Among the bi-encoder models, ColBERT (Khattab and Zaharia, 2020) is a representative architecture with state-of-the-art retrieval effectiveness. The scoring function of ColBERT can be written as the maxsim operation: X simMaxSim (q, p) , max Eqi * Epj , (2) i\u2208|q| j\u2208|p| where Eqi and Epj denotes the i-th and j-th BERT contextualized query and passage token embeddings, respectively. This is known as the MaxSim operation which leverages all the token information of BERT, as shown in Fig. 2(a). Despite of its effectiveness, ColBERT requires to store all the token embeddings in the corpus for offline score computation.\u00bb\\n[3] \u00ab2209.01335v1.txt | Neural machine translations of MS MARCO passages are used to fine-tune the model. 1 Introduction ColBERT (Khattab and Zaharia, 2020) is a dense retrieval model for performing retrieval over English documents with queries written in English. It is designed as a two-stage retrieval model that (1) selects a set of candidate passages using an approximate nearest neighbor approach and (2) ranks those passages based on the sum of the most similar terms to each term in the query.\u00bb\\n[4] \u00ab2201.08471v1.txt | 3 ColBERT-X ColBERT is a multi-stage dense retrieval model that uses monolingual BERT [7] to encode both query and document terms. It employs a late-interaction mechanism, MaxSim, that computes the similarity between the encoded query and document term representations. Computing MaxSim for every query and document term pair in the collection is not feasible, so ColBERT has two ways to reduce the number of required similarity comparisons: reranking or end-toend retrieval. In reranking, a retrieval system such as BM25 generates an initial ranked list, which is then reranked using ColBERT\\'s MaxSim operation. The disadvantage of such a cascaded pipeline is that the overall recall of the system is limited to the recall of the initial ranked list. In the context of CLIR systems, we face the additional complexity of crossing the language barrier that further affects recall. We thus restricted our work to end-to-end (E2E) retrieval.\u00bb\\n[5] \u00ab2203.13088v1.txt | 7 CONCLUSION In this paper, we proposed ColBERTer, an efficient and effective retrieval model that improves the storage efficiency, the retrieval complexity, and the interpretability of the ColBERT architecture along the effectiveness Pareto frontier. To this end, ColBERTer learns whole-word representations that exclude contextualized stopwords, yielding 2.5\u00d7 fewer vectors than ColBERT while supporting user-friendly query\u2013document scoring patterns at the level of whole words. ColBERTer also uses a multi-task, multi-stage training objective-as well as an optional lexical matching component-that together enable it to aggressively reduce the vector dimension to 1. Extensive empirical evaluation shows that ColBERTer is highly effective on MS MARCO and TREC-DL and highly robust out of domain, while demonstrating highly-competitive storage efficiency with prior dense and sparse models. REFERENCES [1] 2015. Meta-analysis in clinical trials revisited. Contemporary Clinical Trials 45 (2015), 139\u2013145. https://doi.org/10.1016/j.cct.2015.09.002 10th Anniversary Special Issue.\u00bb\\n[6] \u00ab2204.10641v1.txt | [40] presented a dynamic hard negatives mining method applied upon fine-tuned dense retrieval models. Khattab and Zaharia [21] introduced a MaxSim late interaction operation to model the finegrained similarity between queries and documents. Lin et al. [27] proposed to distill from ColBERT\\'s MaxSim operator into a simple dot product to enable a single-step ANN search. Qu et al. [33] introduced three training strategies, i.e., cross-batch negatives, denoised hard negatives, and data augmentation. Although these methods greatly improve the performance of dense retrieval models, they usually need more computational or storage cost that may limit their use.\u00bb\\n[7] \u00ab2112.01488v3.txt | Using the inverted list, ColBERTv2 identifies the passage embeddings close to these centroids, decompresses them, and computes their cosine similarity with every query vector. The scores are then grouped by passage ID for each query vector, and scores corresponding to the same passage are maxreduced. This allows ColBERTv2 to conduct an approximate \"MaxSim\" operation per query vector. This computes a lower-bound on the true MaxSim (\u00a73.1) using the embeddings identified via the inverted list, which resembles the approximation explored for scoring by Macdonald and Tonellotto (2021) but is applied for candidate generation. These lower bounds are summed across the query tokens, and the top-scoring ncandidate candidate passages based on these approximate scores are selected for ranking, which loads the complete set of embeddings of each passage, and conducts the same scoring function using all embeddings per document following Equation 1. The result passages are then sorted by score and returned.\u00bb\\n[8] \u00ab2205.09707v1.txt | 4.5 Fast Kernels: Padding-Free MaxSim & Optimized Decompression Figure 2a shows that index lookup operations are a large source of overhead for vanilla ColBERTv2. One reason these lookups are expensive is that they require reshaping and padding the 2D index tensors with an extra dimension representing the maximum passage length. The resulting 3D tensors facilitate batched MaxSim operations over ragged lists of token vectors. To avoid this padding, we instead implement custom C++ code that directly computes the MaxSim scores over the packed 2D index tensors (i.e., one where many 2D sub-tensors of various lengths are concatenated along the same dimension). Our kernel loops over each passage\\'s corresponding\u00bb\\n\\nQuestion: ColBERT Information Retrieval\\n\\nRationale: Let\\'s think step by step.', 'temperature': 0.7, 'top_p': 1}"}}