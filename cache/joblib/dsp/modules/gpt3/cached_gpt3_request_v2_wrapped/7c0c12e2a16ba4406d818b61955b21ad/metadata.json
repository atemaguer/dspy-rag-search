{"duration": 5.379880905151367, "input_args": {"**": "{'frequency_penalty': 0, 'logprobs': 5, 'max_tokens': 150, 'model': 'text-davinci-002', 'n': 20, 'presence_penalty': 0, 'prompt': 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which award did the first book of Gary Zukav receive?\\nAnswer: U.S. National Book Award\\n\\nQuestion: The heir to the Du Pont family fortune sponsored what wrestling team?\\nAnswer: Foxcatcher\\n\\nQuestion: Who was the director of the 2009 movie featuring Peter Outerbridge as William Easton?\\nAnswer: Kevin Greutert\\n\\nQuestion: Who produced the album that included a re-recording of \"Lithium\"?\\nAnswer: Butch Vig\\n\\nQuestion: What city was the victim of Joseph Druces working in?\\nAnswer: Boston, Massachusetts\\n\\nQuestion: In what year was the star of To Hell and Back born?\\nAnswer: 1925\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n[1] \u00ab2207.12515v1.txt | \u2022 Big Models: Recently, Foundation Models such as Large Language Models (LLM) have achieved surprisingly good performance in many AI sub-fields, which have the advantages of emergent capabilities from model size, extracting useful information based on self-supervision, unifying various downstream tasks based on pre-training, fine-tuning and prompting, as well as generalizing to zero-shot or few-shot cases [31, 290]. Many powerful foundation models have been developed for natural language tasks such as T5 [231], GPT-3 [35], OPT [335] and PaLM [69], which show impressive performance on language understanding, generation and reasoning tasks.\u00bb\\n[2] \u00ab2212.09597v1.txt | Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. Emergent abilities of large language models. CoRR, abs/2206.07682. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, December 6-14, 2022, virtual. Peifeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen, and Xiang Ren. 2022c. PINTO: faithful language reasoning using prompt-generated rationales. CoRR, abs/2211.01562.\u00bb\\n[3] \u00ab2212.09597v1.txt | 6 Future Directions Even though numerous works have been proposed for reasoning with language model prompting, there remain some potential directions: Theoretical Principle of Reasoning. LMs have been demonstrated to have emergent zero-shot learning and reasoning abilities (Wei et al., 2022b; Wang et al., 2022g; Wei et al., 2022a). To uncover the mystery of such a success, many researchers have empirically explored the role of in-context learning (Ye and Durrett, 2022; Liu et al., 2022a) and rationales (Min et\u00bb\\n[4] \u00ab2210.05075v1.txt | Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models. ArXiv, abs/2206.07682, 2022a. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022b. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pp. 38\u201345, 2020.\u00bb\\n[5] \u00ab2207.12515v1.txt | 2013. Scrutable user models and personalised item recommendation in mobile lifestyle applications. In International Conference on User Modeling, Adaptation, and Personalization. Springer, 77\u201388. [290] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent Abilities of Large Language Models. arXiv preprint arXiv:2206.07682 (2022). [291] Gerhard Weikum, Xin Luna Dong, Simon Razniewski, Fabian Suchanek, et al. 2021. Machine knowledge: Creation and curation of comprehensive knowledge bases. Foundations and Trends\u00ae in Databases 10, 2-4 (2021), 108\u2013490. [292] Udi Weinsberg, Smriti Bhagat, Stratis Ioannidis, and Nina Taft. 2012. s. In Proceedings of the sixth ACM conference on Recommender systems. 195\u2013202. [293] Chad Williams and Bamshad Mobasher. 2006. Profile injection attack detection for securing collaborative recommender systems. DePaul University CTI Technical Report (2006), 1\u201347.\u00bb\\n[6] \u00ab2212.09597v1.txt | Single-Stage. Early works leverage templatebased prompts (Paranjape et al., 2021; Rajagopal et al., 2021) for reasoning in NLP. Regarding the strong in-context learning ability of large language models (Brown et al., 2020), Wei et al. (2022b) proposes CoT prompting, which adds a series of intermediate reasoning steps, also called CoT, into exemplars of few-shot prompt to induce large language models to generate a reasoning process before answering. Experiments demonstrate that large language models emerge with impressive reasoning abilities with CoT prompting.\u00bb\\n\\nQuestion: Emergent Abilities in Language Models\\n\\nRationale: Let\\'s think step by step.', 'temperature': 0.7, 'top_p': 1}"}}